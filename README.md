# ðŸ‡®ðŸ‡³ Build for Bharat â€” Data Ingestion Layer

This repository implements a **local, agent-based data intelligence pipeline** for accessing live datasets from [data.gov.in](https://data.gov.in).  
It powers the *BharatGPT* prototype â€” a self-contained Q&A system that connects user prompts to official Indian government datasets.

## ðŸŒ Overview

### ðŸ”¹ What it does
- Fetches **live metadata** from data.gov.in using the hidden JSON API  
  `https://www.data.gov.in/backend/dmspublic/v1/resources`
- Builds a **local DuckDB index** of all datasets under:
  - **Ministry of Agriculture and Farmers Welfare**
  - **India Meteorological Department (IMD)**  
- Enables **offline dataset search and retrieval** using titles and notes.

### ðŸ”¹ Why it matters
This forms the foundation for a fully local, transparent AI system that can:
> *â€œAnswer questions about Indian datasets â€” without internet, without APIs, and without scraping.â€*

## ðŸ§© Architecture
```
bharatgpt/
â”œâ”€â”€ connectors/
â”‚   â””â”€â”€ ogdp_scraper.py          â† Fetches metadata from data.gov.in
â”œâ”€â”€ indexer/
â”‚   â”œâ”€â”€ metadata_index.py        â† DuckDB-based metadata store
â”‚   â””â”€â”€ dataset_selector.py      â† Keyword/semantic dataset search
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ demo_scraper.py          â† Builds the initial local index
â”‚   â””â”€â”€ demo_query.py            â† Tests dataset retrieval
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ogdp_index.db            â† Local DuckDB database (auto-created)
â””â”€â”€ utils/
    â””â”€â”€ helpers.py               â† Utility functions (timestamp, I/O)
```

## âš™ï¸ Usage

### 1ï¸âƒ£ Setup
```bash
pip install duckdb requests pandas
```
### 2ï¸âƒ£ Run the scraper
```bash
python -m dataHandlers.demo.demo_scraper
```
This populates `data/ogdp_index.db` with live datasets from both ministries.

### 3ï¸âƒ£ Query datasets
```bash
python -m dataHandlers.connectors.temp
```
or
```python
from dataHandlers.indexer.dataset_selector import DatasetSelector

selector = DatasetSelector()
results = selector.search("rainfall data 2025", limit=5)
for r in results:
    print(r["title"], "->", r["id"])
```
## ðŸ§  Next Steps
- [ ] Add **semantic embeddings** for intelligent dataset selection  
- [ ] Add **DataFetcher** (load CSV/JSON into pandas)  
- [ ] Add **Analyzer Agent** (aggregate, summarize, visualize)  
- [ ] Integrate with a local LLM (Mistral / Phi / Ollama)  
- [ ] Build CLI / web chat interface

## ðŸ“¦ Local Data Policy
All dataset metadata and content are fetched from public data.gov.in resources and stored locally for research and development purposes.  
This system performs no unauthorized scraping or login-based access.
"""
